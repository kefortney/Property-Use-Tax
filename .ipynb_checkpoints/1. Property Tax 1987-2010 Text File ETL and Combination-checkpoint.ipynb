{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Project\n",
    "\n",
    "There are Propert Tax Tranfer records for 1987 to 2010 which need to be transformed into a form that can be joined with current XML based schema in order to create the most comprehensive database as possible. These records date to the beginning of digitalized records and suffer from numerous problems due to their age (like the fact they face Y2K issues with their date format).  \n",
    "\n",
    "\n",
    "# The Goal\n",
    "At the end of this notebook there are two file produced, one with a list of property records, and the second is a list of buyers and sellers. These files are flat files, but due to their size they cannot be stored in Github so the notebook must be downloaded locally and run. Once run the two files will be saved as csv's.  \n",
    "\n",
    "## Loading Records from 1987 to 2010\n",
    "Once compiled into a single dataframe there are a total of 2,350,630 rows. Because of the format of the data there are multiple lines per property transfer, so the actual count of properties is only 681,377 which means on average there are 3 lines or more per property, indicating there is more than just a single seller and buyer.\n",
    "\n",
    "The format of the original data is as a fixed-width text file which was converted in excel into columns based on the file specifications.  In the steps below those columns are adjusted and modified to match the current xml format as best as possible.  \n",
    "\n",
    "## Issues With the Data\n",
    "\n",
    "There are a lot of missing datapoints in the earlier records. Few had SPAN numbers and addresses of the actual properties were sparse in details, like for example, \"OFF LAKE ST IN ADDISON VT\" or \"FORMER DOLPHIS SWEENEY & AVIS SWEENEY HOMEPLACE IN SO ALBANY VILLAGE\". Given the lack of a SPAN number, or any GPS coordinates there is sustantial work to rectefy those records. For those who did have SPAN ids' they were in with other data in an acerage field and were split into their own column. 999-000-00000 was the span ID for 101,333 records, and 2,246,916 had no SPAN at all. Even in 2010 there were 4,400 rows that had 9999-00-00000 as the Span.\n",
    "\n",
    "Monetary values were also stored as cents, in order to match the newer format all those values were converted to dollar amounts as a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the csv version of the text files\n",
    "df87 = pd.read_csv('PT1987.csv', header=None, low_memory=False)\n",
    "df88 = pd.read_csv('PT1988.csv', header=None, low_memory=False)\n",
    "df89 = pd.read_csv('PT1989.csv', header=None, low_memory=False)\n",
    "df90 = pd.read_csv('PT1990.csv', header=None, low_memory=False)\n",
    "df91 = pd.read_csv('PT1991.csv', header=None, low_memory=False)\n",
    "df92 = pd.read_csv('PT1992.csv', header=None, low_memory=False)\n",
    "df93 = pd.read_csv('PT1993.csv', header=None, low_memory=False)\n",
    "df94 = pd.read_csv('PT1994.csv', header=None, low_memory=False)\n",
    "df95 = pd.read_csv('PT1995.csv', header=None, low_memory=False)\n",
    "df96 = pd.read_csv('PT1996.csv', header=None, low_memory=False)\n",
    "df97 = pd.read_csv('PT1997.csv', header=None, low_memory=False)\n",
    "df98 = pd.read_csv('PT1998.csv', header=None, low_memory=False)\n",
    "df99 = pd.read_csv('PT1999.csv', header=None, low_memory=False)\n",
    "df00 = pd.read_csv('PT2000.csv', header=None, low_memory=False)\n",
    "df01 = pd.read_csv('PT2001.csv', header=None, low_memory=False)\n",
    "df02 = pd.read_csv('PT2002.csv', header=None, low_memory=False)\n",
    "df03 = pd.read_csv('PT2003.csv', header=None, low_memory=False)\n",
    "df04 = pd.read_csv('PT2004.csv', header=None, low_memory=False)\n",
    "df05 = pd.read_csv('PT2005.csv', header=None, low_memory=False)\n",
    "df06 = pd.read_csv('PT2006.csv', header=None, low_memory=False)\n",
    "df07 = pd.read_csv('PT2007.csv', header=None, low_memory=False)\n",
    "df08 = pd.read_csv('PT2008.csv', header=None, low_memory=False)\n",
    "df09 = pd.read_csv('PT2009.csv', header=None, low_memory=False)\n",
    "df10 = pd.read_csv('PT2010.csv', header=None, low_memory=False)\n",
    "\n",
    "# append all the years to the first year\n",
    "df = df87.copy()\n",
    "dflist = [df88, df89, df90, df91, df92, df93, df94, df95, df96, df97, df98, df99, df00, df01, df02, df03, df04, df05, df06, df07, df08, df09, df10]\n",
    "df = df.append(dflist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Records:  2350630\n",
      "Total number of Properties:  681337\n"
     ]
    }
   ],
   "source": [
    "#Name and Add Correct Headers\n",
    "col = (\"Key Town Code\", \"Key Year/Month\", \"Key Year\", \"Key Document\", \"Key Record ID\", \"Update Count\", \"S/B\", \"Filler1\", \"Alt Key\", \"Name\", \"Street\", \n",
    "       \"City\", \"State\", \"Zip Code\", \"Country\", \"County/Town Code\", \"Return\", \"Number\", \"Development Rights\", \"Family Member Sale\", \"Financing\", \n",
    "       \"Purchased by Tenant\", \"Buyer Has Adjoining Prop\", \"Property Location 1\", \"Property Location Code\", \n",
    "       \"Transfer Type\", \"Acreage\", \"Frontage\", \"Depth\", \"Building Code 1\", \"Building Code 2\", \"Building Code 3\", \"Number of Apartments\", \n",
    "       \"Use Before\", \"Use After\", \"Exemption Code\", \"Total Selling Price\", \"Personal Property\", \"Real Value\", \"Tax Due\", \"Tax Paid\", \n",
    "       \"Special Circumstances\", \"Valid Sales Flag\", \"Acquired Date\", \"Filler2\", \"Category Code\", \"Per Cent Interest\", \"Filler3\", \"Land Gains Code 1\", \n",
    "       \"Land Gains Code 2\", \"Land Gains Code 3\", \"Span\", \"Act 291 Permit\", \"Act 291 Exempt\", \"Act 250 Permit\", \"Act 250 Exempt\", \"Town Name\", \"Leading0\", \n",
    "       \"Date of Record\", \"Book Number\", \"Page Number\", \"Listed Value\", \"Leading1\",\"Listed Year\", \"Filler5\", \"Withholding Reason \", \n",
    "       \"Certificate Number\", \"Batch Number\", \"leading2\",\"Date Processed\", \"Incomplete Flag\", \"Sub Division\", \"Map/Parcel Number\", \"Date of Closing\", \"Filler6\", \n",
    "       \"Old Form Code\", \"Current Use Code\", \"Previously Occupied\", \"Residential Value\", \"Use Value\", \"Working Farm Value\", \"Filler7\",\"unknown1\")\n",
    "df.columns = col\n",
    "\n",
    "#Split out span and acreage from Filler4 area, named Span\n",
    "df['Acreage-D2'] = df['Span'].str[13:22]\n",
    "df['Span'] = df['Span'].str[:13]\n",
    "\n",
    "#adjust acreage to correct decimel point\n",
    "df['Acreage'] = df['Acreage']*.1\n",
    "df['Acreage-D2'] = pd.to_numeric(df['Acreage-D2'])\n",
    "df['Acreage-D2'] = df['Acreage-D2']*.01\n",
    "\n",
    "# cuts out some empty columns\n",
    "df = df[['Key Town Code', 'Key Year/Month', 'Key Year', 'Key Document', 'Key Record ID', 'Update Count', 'S/B', 'Alt Key', 'Name', 'Street', 'City', 'State', 'Zip Code', 'Country', 'County/Town Code',\n",
    "         'Return', 'Number', 'Development Rights', 'Family Member Sale', 'Financing', 'Purchased by Tenant', 'Buyer Has Adjoining Prop', 'Property Location 1', 'Property Location Code', 'Transfer Type', \n",
    "         'Acreage', 'Frontage', 'Depth', 'Building Code 1', 'Building Code 2', 'Building Code 3', 'Number of Apartments', 'Use Before', 'Use After', 'Exemption Code', 'Total Selling Price', \n",
    "         'Personal Property', 'Real Value', 'Tax Due', 'Tax Paid', 'Special Circumstances', 'Valid Sales Flag', 'Acquired Date', 'Category Code', 'Per Cent Interest', 'Land Gains Code 1', \n",
    "         'Land Gains Code 2', 'Land Gains Code 3', 'Span', 'Act 291 Permit', 'Act 291 Exempt', 'Act 250 Permit', 'Act 250 Exempt', 'Town Name', 'Date of Record', 'Book Number', 'Page Number', \n",
    "         'Listed Value', 'Listed Year', 'Withholding Reason ', 'Certificate Number', 'Batch Number', 'Date Processed', 'Incomplete Flag', 'Sub Division', 'Map/Parcel Number', 'Date of Closing', \n",
    "         'Old Form Code', 'Current Use Code', 'Previously Occupied', 'Residential Value', 'Use Value','Working Farm Value',  'unknown1', 'Acreage-D2']]\n",
    "\n",
    "# changes prices to be in dollars rather than cents\n",
    "df['Total Selling Price'] = df['Total Selling Price']*0.01\n",
    "df['Personal Property'] = df['Personal Property']*0.01\n",
    "df['Real Value'] = df['Real Value']*0.01\n",
    "df['Tax Due'] = df['Tax Due']*0.01\n",
    "df['Tax Paid'] = df['Tax Paid']*0.01\n",
    "df['Use Value'] = df['Use Value']*0.01\n",
    "\n",
    "print(\"Total number of Records: \", len(df))\n",
    "print(\"Total number of Properties: \", len(df[df['Key Record ID'] == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group By Span, sorted by Count\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Span</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86542</th>\n",
       "      <td>999-000-00000</td>\n",
       "      <td>101333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86541</th>\n",
       "      <td>998-000-00000</td>\n",
       "      <td>885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76776</th>\n",
       "      <td>690-219-13481</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40045</th>\n",
       "      <td>363-112-13517</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63973</th>\n",
       "      <td>588-185-10973</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40078</th>\n",
       "      <td>363-112-13607</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64496</th>\n",
       "      <td>588-185-13320</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76762</th>\n",
       "      <td>690-219-13413</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70628</th>\n",
       "      <td>621-195-13479</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70739</th>\n",
       "      <td>621-195-13828</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Span   count\n",
       "86542  999-000-00000  101333\n",
       "86541  998-000-00000     885\n",
       "76776  690-219-13481     177\n",
       "40045  363-112-13517     174\n",
       "63973  588-185-10973     167\n",
       "40078  363-112-13607     137\n",
       "64496  588-185-13320     137\n",
       "76762  690-219-13413     111\n",
       "70628  621-195-13479      99\n",
       "70739  621-195-13828      49"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Group By Span, sorted by Count\")\n",
    "df['count'] = 1\n",
    "df[['Span','count']].groupby(['Span'], as_index=0).sum().sort_values('count', ascending=0).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date\n",
    "\n",
    "These records did not have a DNL field at all. In order to import into the modern form a DNL had to be created which required that all the dates be updated to 4 year digits. Additionaly given the age of these records they suffered some data integrety loss for dates, as dates were not done with a 4 digit format (YYYY) and some of those dates seem to be wildly inaccurate.  Additionally the importing of this data into excel then into Pandas meant the leading zeros were dropped so those had to be readded. \n",
    "\n",
    "There were four fields with data records, none have dates for all records. \n",
    "* Date Processed - 658265 records with dates\n",
    "* Date of Record - 657050 records with dates \n",
    "* Date of Closing - 528926 records with dates \n",
    "* Acquired Date - 498122 records with dates\n",
    "\n",
    "If a Date Processed had an odd value that does not match actual potential years, the 19000000 was put in place.\n",
    "\n",
    "The Date of Closing also had some odd values that produced errors that had to be coerced. Some of the months were outside of 1-12 so for those it was defaulted to the month of 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the automatic float format to int in order to try to convert to the correct date\n",
    "datefield = ['Date of Record','Date Processed','Date of Closing','Acquired Date']\n",
    "\n",
    "for x in datefield:\n",
    "    df[x] = df[x].fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DNL'] = df['Date Processed']\n",
    "\n",
    "datefield = ['DNL','Date of Record','Date Processed','Date of Closing','Acquired Date']\n",
    "\n",
    "# Due to leading zeros being dropped in import and that this has only a two digit date, determine and add the correct year \n",
    "def addyear(date):\n",
    "    for x in date:\n",
    "        if len(str(x)) == 3:\n",
    "            y.append(int(\"20000\" + str(x)))\n",
    "        elif len(str(x)) == 4:\n",
    "            y.append(int(\"2000\" + str(x)))\n",
    "        elif len(str(x)) == 5:\n",
    "             y.append(int(\"200\" + str(x)))\n",
    "        elif (len(str(x)) == 6) & (int(x) >= 100101) & (int(x) <= 101231):\n",
    "            y.append(int(\"20\" + str(x)))\n",
    "        elif (len(str(x)) == 6) & (int(x) > 101231) & (int(x) <= 991231):\n",
    "            y.append(int(\"19\" + str(x)))\n",
    "        else:\n",
    "            y.append(0)\n",
    "\n",
    "for x in datefield:\n",
    "    y=[]\n",
    "    addyear(df[x])\n",
    "    df[x] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the dates into \"-\" split dates to it could be converted to datetime format and match xml\n",
    "def splitdate(date):\n",
    "    for x in date:\n",
    "        if x == 0:\n",
    "            y.append(x)\n",
    "        else:\n",
    "            x = str(x)\n",
    "            y.append(x[0:4] + \"-\" + x[4:6] + \"-\" +  x[6:8])\n",
    "\n",
    "y = []\n",
    "splitdate(df['Date Processed'])\n",
    "df['Date Processed'] = y\n",
    "\n",
    "y = []\n",
    "splitdate(df['Date of Record'])\n",
    "df['Date of Record'] = y\n",
    "\n",
    "y = []\n",
    "splitdate(df['Date of Closing'])\n",
    "df['Date of Closing'] = y\n",
    "\n",
    "y = []\n",
    "splitdate(df['Acquired Date'])\n",
    "df['Acquired Date'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNL\n",
    "\n",
    "None of these records had DNL ids, a DNL record was create from the Date Processed, Key Document number and for trailing zeros. These seems to match the format of later records as best as possible and should provide a unique not duplicated by later records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key Town Code</th>\n",
       "      <th>Key Year/Month</th>\n",
       "      <th>Key Year</th>\n",
       "      <th>Key Document</th>\n",
       "      <th>Key Record ID</th>\n",
       "      <th>Update Count</th>\n",
       "      <th>S/B</th>\n",
       "      <th>Alt Key</th>\n",
       "      <th>Name</th>\n",
       "      <th>Street</th>\n",
       "      <th>...</th>\n",
       "      <th>Old Form Code</th>\n",
       "      <th>Current Use Code</th>\n",
       "      <th>Previously Occupied</th>\n",
       "      <th>Residential Value</th>\n",
       "      <th>Use Value</th>\n",
       "      <th>Working Farm Value</th>\n",
       "      <th>unknown1</th>\n",
       "      <th>Acreage-D2</th>\n",
       "      <th>count</th>\n",
       "      <th>DNL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62688</th>\n",
       "      <td>NO</td>\n",
       "      <td>ENTR</td>\n",
       "      <td>IE</td>\n",
       "      <td>S MADE</td>\n",
       "      <td>T</td>\n",
       "      <td>HIS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/200176201</td>\n",
       "      <td>060237244700000S00000000000237244700</td>\n",
       "      <td>HAYNES LINCOLN W TRUST</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10927.0</td>\n",
       "      <td>20210.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40060160490000000000000000000000    X</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Key Town Code Key Year/Month Key Year Key Document Key Record ID  \\\n",
       "62688            NO           ENTR       IE       S MADE             T   \n",
       "\n",
       "      Update Count  S/B     Alt Key                                  Name  \\\n",
       "62688          HIS  NaN  /200176201  060237244700000S00000000000237244700   \n",
       "\n",
       "                       Street ... Old Form Code Current Use Code  \\\n",
       "62688  HAYNES LINCOLN W TRUST ...           5.0                0   \n",
       "\n",
       "      Previously Occupied Residential Value  Use Value Working Farm Value  \\\n",
       "62688                   6           10927.0   20210.31                0.0   \n",
       "\n",
       "                                    unknown1 Acreage-D2 count DNL  \n",
       "62688  40060160490000000000000000000000    X  1600000.0     1   0  \n",
       "\n",
       "[1 rows x 77 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Key Document'] == 'S MADE'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'S MADE'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-60b630a795ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Key Document'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Key Document'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[0;32m   4999\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5000\u001b[0m             new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[1;32m-> 5001\u001b[1;33m                                          **kwargs)\n\u001b[0m\u001b[0;32m   5002\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m   3712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3713\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3714\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'astype'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3716\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m   3579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3580\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mgr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3581\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3582\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'raise'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[1;32m--> 575\u001b[1;33m                             **kwargs)\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_astype\u001b[1;34m(self, dtype, copy, errors, values, klass, mgr, **kwargs)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m                 \u001b[1;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 664\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    665\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy)\u001b[0m\n\u001b[0;32m    707\u001b[0m         \u001b[1;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype_intsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m         \u001b[1;31m# if we have a datetime/timedelta array of objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/src\\util.pxd\u001b[0m in \u001b[0;36mutil.set_value_at_unsafe\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'S MADE'"
     ]
    }
   ],
   "source": [
    "\n",
    "y = []\n",
    "for x in df['Key Document']:\n",
    "    if x == 'S MADE':\n",
    "         y.append(100000)\n",
    "    elif (len(str(x)) ==  6) and type(x) == \"int\":\n",
    "        y.append(x)\n",
    "    else:\n",
    "        y.append(100000)\n",
    "        \n",
    "df['Key Document'] = df['Key Document'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dnl number with Date Processed and Key Document number        \n",
    "df['DNL']= df['DNL'].astype(float)\n",
    "df['DNL'] = df['DNL'].replace(0.0,np.nan)\n",
    "df['DNL'].fillna(method='ffill', inplace=True)\n",
    "df['DNL']= df['DNL'].astype(int)\n",
    "df['DNL'] = df['DNL'].astype(str) \n",
    "\n",
    "x = []\n",
    "for num in df['DNL']:\n",
    "    x.append(num + '0000')\n",
    "df['DNL'] = x    \n",
    "df['Key Document'] = df['Key Document'].astype(str)    \n",
    "df['DNL'] = df['DNL'] +  df['Key Document']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DNL'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Financing section into Columns\n",
    "Certain types of records were stored as numeric values rather than binary columns. In oder for it tom \n",
    "* Space=Unknown\n",
    "* 1=Bank\n",
    "* 2=Owner\n",
    "* 3=Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing bad data entry and replacing 9 with zero as it is not clear what that would stnad for\n",
    "df['Financing'].replace(\"O\",0, inplace=True)\n",
    "df['Financing'].replace(9,0, inplace=True)\n",
    "df['Financing'] = df['Financing'].fillna(0).astype(int)\n",
    "\n",
    "financing = pd.get_dummies(df['Financing'])\n",
    "financing.columns = ['Unknown','Bank','Owner','Other']\n",
    "df = pd.concat([df,financing], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Property File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proponlydf = df[df['Key Record ID'] == 0]\n",
    "len(proponlydf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to datetime felts\n",
    "proponlydf['Date Processed'] = pd.to_datetime(proponlydf['Date Processed'], infer_datetime_format=True)\n",
    "proponlydf['Date of Record'] = pd.to_datetime(proponlydf['Date of Record'], infer_datetime_format=True)\n",
    "proponlydf['Acquired Date'] = pd.to_datetime(proponlydf['Acquired Date'], infer_datetime_format=True)\n",
    "proponlydf['Date of Closing'] = pd.to_datetime(proponlydf['Date of Closing'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnname = ['receivedDate','postedDate','DLN','totalSellers','totalBuyers','internationalAddress','propertyLocationStreet','propertyLocationCity',\n",
    "              'closingDate’,’interestPropertyType','interestUndivPercent','landSize','specialFactorsDevRights','specialFactorsRelationship',\n",
    "              'financingBank','financingOwner','financingOther','buildingTypeNone','buildingTypeSingle','buildingTypeSeasonal','buildingTypeFarm',\n",
    "              'buildingTypeMultiFamily','buildingTypeMultiUnit','buildingTypeMobile','buildingTypeCondo','buildingTypeConUnit','buildingTypeFactory',\n",
    "              'buildingTypeStore','buildingTypeNewCons','buildingTypeOther','sellerUseOfProperty','rentedBefore','buyerUseOfProperty','specialCircumCode',\n",
    "              'legacyBuyerUseOfProperty','legacySellerUseOfProperty','rentedAfter','tenantPurchase','buyerAdjoiningProperty','currentUseValueLien',\n",
    "              'currentUseEnrollmentContinue','propertyTaxExemption','totalPricePaid','personalPropertyPricePaid','realPropertyPricePaid',\n",
    "              'principalResidenceValue','currentUseMarketValue','qualifiedFarmValue','taxDue','dateSellerAcquired','noLandGainsTaxReturn1',\n",
    "              'noLandGainsTaxReturn2','noLandGainsTaxReturn3','city','dateOfRecord','listedValue','parcelIDNo','grandListCategory','span',\n",
    "              'townCode','schoolCode','countyCode']\n",
    "propdf = pd.DataFrame(columns=columnname)\n",
    "propdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propdf['receivedDate'] = proponlydf['Date of Record']\n",
    "propdf['postedDate'] = proponlydf['Date Processed']\n",
    "propdf['DLN'] = proponlydf['DNL']\n",
    "#propdf['totalSellers'] = proponlydf['']\n",
    "#propdf['totalBuyers'] = proponlydf['']\n",
    "propdf['propertyLocationStreet'] = proponlydf['Property Location 1']\n",
    "propdf['propertyLocationCity'] = proponlydf['Town Name']\n",
    "propdf['closingDate'] = proponlydf['Date of Closing']\n",
    "#propdf['interestPropertyType'] = proponlydf['']\n",
    "propdf['interestUndivPercent'] = proponlydf['Per Cent Interest']\n",
    "propdf['landSize'] = proponlydf['Acreage']\n",
    "propdf['specialFactorsDevRights'] = proponlydf['Development Rights']\n",
    "propdf['specialFactorsRelationship'] = np.nan\n",
    "propdf['financingBank'] = proponlydf['Bank']\n",
    "propdf['financingOwner'] = proponlydf['Owner']\n",
    "propdf['financingOther'] = proponlydf['Other']\n",
    "#propdf['buildingTypeNone'] = proponlydf['']\n",
    "#propdf['buildingTypeSingle'] = proponlydf['']\n",
    "#propdf['buildingTypeSeasonal'] = proponlydf['']\n",
    "#propdf['buildingTypeFarm'] = proponlydf['']\n",
    "#propdf['buildingTypeMultiFamily'] = proponlydf['']\n",
    "#propdf['buildingTypeMultiUnit'] = proponlydf['']\n",
    "#propdf['buildingTypeMobile'] = proponlydf['']\n",
    "#propdf['buildingTypeCondo'] = proponlydf['']\n",
    "#propdf['buildingTypeConUnit'] = proponlydf['']\n",
    "#propdf['buildingTypeFactory'] = proponlydf['']\n",
    "#propdf['buildingTypeStore'] = proponlydf['']\n",
    "#propdf['buildingTypeNewCons'] = proponlydf['']\n",
    "#propdf['buildingTypeOther'] = proponlydf['']\n",
    "#propdf['sellerUseOfProperty'] = proponlydf['']\n",
    "propdf['rentedBefore'] = np.nan\n",
    "propdf['buyerUseOfProperty'] = proponlydf['Use Before']\n",
    "propdf['specialCircumCode'] = proponlydf['Special Circumstances']\n",
    "propdf['legacyBuyerUseOfProperty'] = proponlydf['Use After']\n",
    "propdf['legacySellerUseOfProperty'] = proponlydf['Use Before']\n",
    "propdf['rentedAfter'] =  np.nan\n",
    "propdf['tenantPurchase'] = proponlydf['Purchased by Tenant']\n",
    "propdf['buyerAdjoiningProperty'] = proponlydf['Buyer Has Adjoining Prop']\n",
    "propdf['currentUseValueLien'] = np.nan\n",
    "propdf['currentUseEnrollmentContinue'] = np.nan\n",
    "#propdf['propertyTaxExemption'] = proponlydf['Withholding Reason']\n",
    "propdf['totalPricePaid'] = proponlydf['Total Selling Price']\n",
    "propdf['personalPropertyPricePaid'] = proponlydf['Personal Property']\n",
    "propdf['realPropertyPricePaid'] = proponlydf['Real Value']\n",
    "propdf['principalResidenceValue'] = np.nan\n",
    "propdf['currentUseMarketValue'] = proponlydf['Use Value']\n",
    "propdf['qualifiedFarmValue'] = proponlydf['Working Farm Value']\n",
    "propdf['taxDue'] = proponlydf['Tax Due']\n",
    "propdf['dateSellerAcquired'] = proponlydf['Acquired Date']\n",
    "propdf['noLandGainsTaxReturn1'] = proponlydf['Land Gains Code 1']\n",
    "propdf['noLandGainsTaxReturn2'] = proponlydf['Land Gains Code 2']\n",
    "propdf['noLandGainsTaxReturn3'] = proponlydf['Land Gains Code 3']\n",
    "propdf['city'] = proponlydf['City']\n",
    "propdf['dateOfRecord'] = proponlydf['Date of Record']\n",
    "propdf['listedValue'] = proponlydf['Listed Value']\n",
    "propdf['parcelIDNo'] = proponlydf['Map/Parcel Number']\n",
    "propdf['grandListCategory'] = np.nan\n",
    "propdf['span'] = proponlydf['Span']\n",
    "#propdf['townCode'] = proponlydf['']\n",
    "#propdf['schoolCode'] = proponlydf['']\n",
    "#propdf['countyCode'] = proponlydf['']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "propdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recieved = propdf[['receivedDate','postedDate']].groupby(by='receivedDate', as_index=False).count()\n",
    "recieved.columns = ['Date','Count']\n",
    "#sns.countplot(x='receivedDate', y=)\n",
    "#plt.plot(propdf['postedDate'])\n",
    "posted = propdf[['postedDate','receivedDate']].groupby(by='postedDate', as_index=False).count()\n",
    "posted.columns = ['Date','Count']\n",
    "\n",
    "closing = propdf[['closingDate','receivedDate']].groupby(by='closingDate', as_index=False).count()\n",
    "closing.columns = ['Date','Count']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x='Date', y=\"Count\",  data=recieved)\n",
    "sns.relplot(x='Date', y=\"Count\", data=posted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = propdf\n",
    "data = data[(data['realPropertyPricePaid'] > 0) & (data['realPropertyPricePaid'] < 1000000) ]\n",
    "sns.distplot(data['realPropertyPricePaid'], bins=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = propdf\n",
    "data['currentUseMarketValue'] = data['currentUseMarketValue']*.01\n",
    "data = data[(data['currentUseMarketValue'] > 0) & (data['currentUseMarketValue'] < 1000000) ]\n",
    "sns.distplot(data['currentUseMarketValue'], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = propdf\n",
    "data = data[(data['totalPricePaid'] > 0) & (data['totalPricePaid'] < 1000000) ]\n",
    "sns.distplot(data['totalPricePaid'], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = propdf\n",
    "data = data[(data['taxDue'] > 0) & (data['taxDue'] < 10000) ]\n",
    "sns.distplot(data['taxDue'], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = propdf\n",
    "data = data[(data['qualifiedFarmValue'] > 0) & (data['qualifiedFarmValue'] < 10000000000) ]\n",
    "sns.distplot(data['qualifiedFarmValue'], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = df[0:300]\n",
    "\n",
    "#test.to_csv(\"testdf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CATEGORY CODES\n",
    "* 00 UNKNOWN\n",
    "* 01 Residential less than 6 acres\n",
    "* 02 Residential 6 acres or more\n",
    "* 03 Mobile Home without land\n",
    "* 04 Mobile Home with land\n",
    "* 05 Vacation less than 6 acres\n",
    "* 06 Vacation 6 acres or more\n",
    "* 07 Commercial\n",
    "* 08 Not Used\n",
    "* 09 Industrial\n",
    "* 10 Utilities Electric\n",
    "* 11 Utilities Other\n",
    "* 12 Farms\n",
    "* 13 Government Land\n",
    "* 14 Timber/Wood Land\n",
    "* 15 Miscellaneous/Open Land\n",
    "\n",
    "\n",
    "SPECIAL CIRCUMSTANCES CODES\n",
    "* 00 None\n",
    "* 01 Price Paid less than value of land\n",
    "* 02 Straw Transfer\n",
    "* 03 In Lieu of Foreclosure\n",
    "* 04 Real Property is estimate by Tax Dept.\n",
    "* 05 One of Several Returns for one Property\n",
    "* 06 Contract Sales\n",
    "* 07 Burned-out Buildings\n",
    "* 08 Sales between members of the immediate family\n",
    "* 09 Sales between a corporation and a stockholder\n",
    "* 10 Tax sales; Sheriff's sales; Bankruptcy, Receivership, Dissolution or Liquidation sales \n",
    "* 11 Sales by Guardians, Trustees, Executors, and Administrators\n",
    "* 12 Sales to or from the U.S. Government, the State of  Vermont or any Political subdivision of Vermont\n",
    "* 13 Sales to or from any Charitable,  Religious or Benevolent organization\n",
    "* 14 Sales where unusual financing significantly affected sale price\n",
    "* 15 Sales where all assessed interests were not sold, thereby affecting sale price\n",
    "* 16 Sales of Property assessed in more than one town\n",
    "* 17 Any sales that include personal property unless the amount of the personal can be determined and reported\n",
    "* 18 Sales of Property conveying only a portion of the assessed unit, such as a lot or lots sold off from a farm\n",
    "* 19 Sales where the property sold was substantially changed assessment date but prior to date of sale\n",
    "* 20 Other reasons\n",
    "\n",
    "VALID SALES FLAG\n",
    "\n",
    "The Valid Sales Flag is determined by the type of Special Circumstances Code used.\n",
    "\n",
    "CODE Special Circumstances Code\n",
    "* 01 00,01\n",
    "* 02 05,07,11,12,16,18,19,20\n",
    "* 03 02,03,04,06,08,09,10,13,14,15,17\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"wholedf.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
